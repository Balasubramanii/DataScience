{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHzIAjsYT0Gi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd     # handling the data\n",
        "import numpy as np      # handling arrays\n",
        "import matplotlib.pyplot as plt   # plotting the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('student_scores.csv')    # read the dataset"
      ],
      "metadata": {
        "id": "2RpmmiJjW2qK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "fae46ec4-d385-44d8-9937-2e47f87a6d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-02d17642b2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'student_scores.csv'\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# read the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student_scores.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape      # no of rows and columns"
      ],
      "metadata": {
        "id": "0iHYoLYVXKOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "-N2V9XfHXSOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement"
      ],
      "metadata": {
        "id": "pSq_vA7jXYs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the number of hours the student studies and to predict the student's score"
      ],
      "metadata": {
        "id": "iTA6t5HUXb5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I . Data Cleaning"
      ],
      "metadata": {
        "id": "e_GZl5YpYVfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 . Check for missing values"
      ],
      "metadata": {
        "id": "mUWeWPirYZmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()     # count the missing values in each column"
      ],
      "metadata": {
        "id": "NLcPVtvuXbfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 . Delete Duplicates\n",
        "Duplicates means data that are repeated"
      ],
      "metadata": {
        "id": "1vCYLmPQZCqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "h31JqHfzZGik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 . Check for Outliers"
      ],
      "metadata": {
        "id": "r3Un5vTCZW7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "NKfOz5b7YT0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to detect outliers is IQR (i.e) Inter Quantile Range (Box plot)"
      ],
      "metadata": {
        "id": "Y9zZTOaTZk5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iqr = data.Hours.quantile(0.75)-data.Hours.quantile(0.25)"
      ],
      "metadata": {
        "id": "oOLx8FuvclSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "value > q3 + 1.5 (iqr) ----> Outlier\n",
        "value < q1 - 1.5 (iqr) ----> Outlier"
      ],
      "metadata": {
        "id": "GwOwLjQ4c9aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_threshold = data.Hours.quantile(0.75) + 1.5 * iqr\n",
        "lower_threshold = data.Hours.quantile(0.25) - 1.5 * iqr"
      ],
      "metadata": {
        "id": "xg6saFrgdaCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(upper_threshold)      # No values greater than upper threshold in Hours column\n",
        "print(lower_threshold)      # No values lower than lower threshold in Hours column"
      ],
      "metadata": {
        "id": "puKU2KDUdygk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iqr = data.Scores.quantile(0.75)-data.Scores.quantile(0.25)"
      ],
      "metadata": {
        "id": "paKH0AXpeSrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper_threshold = data.Scores.quantile(0.75) + 1.5 * iqr\n",
        "lower_threshold = data.Scores.quantile(0.25) - 1.5 * iqr"
      ],
      "metadata": {
        "id": "3ZykUVEEecNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(upper_threshold)      # No values greater than upper threshold in Scores column\n",
        "print(lower_threshold)      # No values lower than lower threshold in Scores column"
      ],
      "metadata": {
        "id": "LNaEA9T1ekXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 . Check data is in right format or not"
      ],
      "metadata": {
        "id": "bWIjKCQJexNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "hJC_cL0DewUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Data cleaning is done"
      ],
      "metadata": {
        "id": "Tn8opXK4fDcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "II . EDA\n",
        "\n",
        "\n",
        "Find the relationship between Features and Target"
      ],
      "metadata": {
        "id": "VyKehl7ghZp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.plot(x='Hours', y='Scores', style='o')    # both are continuous values so go for scatter plot\n",
        "plt.title('Hours vs Percentage')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Percentage Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fpWca_CEhcNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Is there any relationship between the feature and target - Yes (i.e) hours increases score increases\n",
        "\n",
        "2) Is there any linear relationship between the feature and target - Yes (i.e) there is a st. line relationship\n",
        "\n",
        "3) No transformation is required"
      ],
      "metadata": {
        "id": "Ku2gCFtSiKSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "id": "w9tT4CHMiqO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apart from plotting we can go for Correlation\n",
        "\n",
        "Positive correlation indicates that x increases y also increases.. by using our general knowledge also we can interpret that if a student study for more hours then he will get good score"
      ],
      "metadata": {
        "id": "1vTPGRGHIXhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a linear relationship between hours and score => we can go ahead and develop a linear regression model. No transformation required."
      ],
      "metadata": {
        "id": "Mmu-eYjDIq-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Feature selection is done through EDA only"
      ],
      "metadata": {
        "id": "0Wur20t5I3zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Encoding is required because it is not categorical data"
      ],
      "metadata": {
        "id": "PqtOjJosJHlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "III . Splitting of Data"
      ],
      "metadata": {
        "id": "yX_7wnRhJTbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.loc[:, ['Hours']].values # select all rows and select all columns except the last column as my feature\n",
        "y = data.loc[:, 'Scores'].values # target as arrays\n",
        "# Syntax : dataset.loc[:, :-1]\n",
        "from sklearn.model_selection import train_test_split #import the required function\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "# random state is given to use the same randomness in splitting random_state=3"
      ],
      "metadata": {
        "id": "GpXHmMOaJLK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "metadata": {
        "id": "Zodjj9FT22gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test"
      ],
      "metadata": {
        "id": "gXIZnrD13Ckz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IV . Scaling the Data\n",
        "\n",
        "sclaing is not mandatory for Linear Regression"
      ],
      "metadata": {
        "id": "VhHUDCSKNP0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "V . Modelling Jar"
      ],
      "metadata": {
        "id": "3de_FL-0Nbq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression #importing all the required functions\n",
        "regressor = LinearRegression() # spredicted score = m * hours + c  \n",
        "\"Symtax : varName = ModelName(modelHyperParams)\"\n",
        "regressor.fit(X_train, y_train) #Learning happens - GD is done and we get the final values of m and c"
      ],
      "metadata": {
        "id": "8iv7DdLViNW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(regressor.intercept_) # c"
      ],
      "metadata": {
        "id": "GErSIzckOoCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(regressor.coef_) # slope - m"
      ],
      "metadata": {
        "id": "C2oKtEp8Oqkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " (95 - regressor.intercept_) / regressor.coef_  "
      ],
      "metadata": {
        "id": "by-N40pcrImV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.predict([[5]]) # Given input as studying 5 hours a day"
      ],
      "metadata": {
        "id": "bffN78RsPMxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.predict([[11]])"
      ],
      "metadata": {
        "id": "d-E9evRg48Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum hours student studied is 9.2 hours(data.describe) given in the dataset \n",
        "\n",
        "if u give values greater than max value ML will predict some output but its not guaranteed that the output is correct\n",
        "\n",
        "Perils of extrapolation"
      ],
      "metadata": {
        "id": "94SSk1JC5iF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.Hours.max()"
      ],
      "metadata": {
        "id": "S4SqMUyZ6yMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test) # given the features of the test dataset, it will give the final predictions\n",
        "\"Syntax : varName.predict(test_features)\"\n",
        "y_pred"
      ],
      "metadata": {
        "id": "rFD7UNHh7m2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df"
      ],
      "metadata": {
        "id": "wtP7k_pU7qWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6th JAR\n",
        "\n",
        "for Regression Which is the best ML Model -----> R2\n",
        "higher the r2 better the model\n",
        "\n",
        "max value for r2 ----> 1\n",
        "\n",
        "min valuse for r2 ----> (- infinity) \n",
        "\n",
        "r2 < 0 is waste model ( base_value = 0 )"
      ],
      "metadata": {
        "id": "erICOO3U8gsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "print('R2- SCORE:', metrics.r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "_xHAflMt-vEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.score(X_test,y_test) # another way to get the r^2 values"
      ],
      "metadata": {
        "id": "HhYh258u-wrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}