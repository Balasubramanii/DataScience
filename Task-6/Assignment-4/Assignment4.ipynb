{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vVBLMm0Mo5t"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import phi and phi_test from train and test datasets using NumPy's loadtxt function"
      ],
      "metadata": {
        "id": "52GrMytfNoqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phi = np.loadtxt('train.csv', dtype='float', delimiter=',', skiprows=1,\n",
        "                 usecols=tuple(range(1, 14)))"
      ],
      "metadata": {
        "id": "360TzbSNNpqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XhTvmatYjSN",
        "outputId": "2e7907ef-2b3b-4f7c-d4b1-9416e16e98d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.06411199e-02, 0.00000000e+00, 2.81524927e-01, ...,\n",
              "        7.71748449e-01, 4.26074896e-01, 1.00000000e+00],\n",
              "       [2.21317669e-04, 2.94736842e-01, 5.34457478e-01, ...,\n",
              "        9.98562711e-01, 1.19001387e-01, 1.00000000e+00],\n",
              "       [1.36513324e-02, 0.00000000e+00, 7.00879765e-01, ...,\n",
              "        9.15603409e-01, 7.40638003e-02, 1.00000000e+00],\n",
              "       ...,\n",
              "       [7.47001646e-02, 0.00000000e+00, 6.46627566e-01, ...,\n",
              "        1.00000000e+00, 3.34812760e-01, 1.00000000e+00],\n",
              "       [1.37252923e-03, 0.00000000e+00, 2.96920821e-01, ...,\n",
              "        9.76776439e-01, 3.37586685e-01, 1.00000000e+00],\n",
              "       [6.24949841e-04, 7.36842105e-01, 6.52492669e-02, ...,\n",
              "        9.27732110e-01, 8.46047157e-02, 1.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phi_test = np.loadtxt('test.csv', dtype='float', delimiter=',',\n",
        "                      skiprows=1, usecols=tuple(range(1, 14)))"
      ],
      "metadata": {
        "id": "HguV-GgSN08M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phi_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjvnmGCtYlJI",
        "outputId": "323d1793-3d5d-428d-a9f1-e3cd348f4717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.09096460e-03, 3.15789474e-01, 1.63856305e-01, ...,\n",
              "        9.94250845e-01, 2.90707351e-01, 1.00000000e+00],\n",
              "       [3.73205208e-03, 0.00000000e+00, 2.53665689e-01, ...,\n",
              "        1.00000000e+00, 1.16504854e-01, 1.00000000e+00],\n",
              "       [1.37557979e-01, 0.00000000e+00, 6.46627566e-01, ...,\n",
              "        6.13495386e-02, 3.81969487e-01, 1.00000000e+00],\n",
              "       ...,\n",
              "       [5.00634279e-04, 2.21052632e-01, 1.89882698e-01, ...,\n",
              "        1.00000000e+00, 9.32038835e-02, 1.00000000e+00],\n",
              "       [1.07489125e-03, 4.21052632e-01, 2.18108504e-01, ...,\n",
              "        9.80710071e-01, 1.14563107e-01, 1.00000000e+00],\n",
              "       [5.11066221e-02, 0.00000000e+00, 6.46627566e-01, ...,\n",
              "        8.93590196e-01, 1.44244105e-01, 1.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import y from train dataset using the loadtxt function"
      ],
      "metadata": {
        "id": "_iWCVOCMN52d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.loadtxt('train.csv', dtype='float', delimiter=',', skiprows=1,\n",
        "               usecols=14, ndmin=2)"
      ],
      "metadata": {
        "id": "R0mPH7y0N6Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate coloumn of 1s to right of phi and phi_test"
      ],
      "metadata": {
        "id": "4XDXMOsVOAv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phi_test = np.concatenate((phi_test, np.ones((105, 1))), axis=1)\n",
        "phi = np.concatenate((phi, np.ones((400, 1))), axis=1)"
      ],
      "metadata": {
        "id": "I8DGJaCMODpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply min max scaling on each coloumn of phi and phi_test"
      ],
      "metadata": {
        "id": "jrn1LWm_OHIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(13):\n",
        "    col_max = max(phi[:, i])\n",
        "    col_min = min(phi[:, i])\n",
        "    phi[:, i] = (phi[:, i] - col_min) / (col_max - col_min)\n",
        "    phi_test[:, i] = (phi_test[:, i] - col_min) / (col_max - col_min)"
      ],
      "metadata": {
        "id": "WicP3HzBOIbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply log scaling on y"
      ],
      "metadata": {
        "id": "_SPDhA23OMkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.log(y)"
      ],
      "metadata": {
        "id": "jcbsg1YPOL4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to calculate change in error function based on phi, w and p norm"
      ],
      "metadata": {
        "id": "mycftshhOQj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delta_w(p, phi, w):\n",
        "    if p == 2:\n",
        "        deltaw = (2 * (np.dot(np.dot(np.transpose(phi), phi), w) -\n",
        "                       np.dot(np.transpose(phi), y)) +\n",
        "                  lambd * p * np.power(np.absolute(w), (p - 1)))\n",
        "    if p < 2 and p > 1:\n",
        "        deltaw = (2 * (np.dot(np.dot(np.transpose(phi), phi), w) -\n",
        "                       np.dot(np.transpose(phi), y)) +\n",
        "                  lambd * p * np.power(np.absolute(w), (p - 1)) * np.sign(w))\n",
        "    return deltaw"
      ],
      "metadata": {
        "id": "0qQCi7qiOYRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a dictionary containing filenames as keys and p as values"
      ],
      "metadata": {
        "id": "wQhB_nEROgTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = {'output.csv': 2.0,\n",
        "             'output_p1.csv': 1.75,\n",
        "             'output_p2.csv': 1.5,\n",
        "             'output_p3.csv': 1.3\n",
        "             }"
      ],
      "metadata": {
        "id": "ACg4sFL4Oguh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each item in this dictionary:\n",
        "\n",
        "Set the w to all 0s"
      ],
      "metadata": {
        "id": "RtQbghNgOkWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (fname, p) in filenames.items():\n",
        "    # Set initial w to zeros\n",
        "    w = np.zeros((14, 1))\n",
        "\n",
        "    # Hyperparameter lambda value\n",
        "    lambd = 0.2\n",
        "\n",
        "    # Maximum step size\n",
        "    t = 0.00012\n",
        "\n",
        "    # Calculate new value of w\n",
        "    w_new = w - t * delta_w(p, phi, w)\n",
        "\n",
        "    i = 0\n",
        "    # Repeat steps until error between consecutive w is less than threshold\n",
        "    while(np.linalg.norm(w_new-w) > 10 ** -10):\n",
        "        w = w_new\n",
        "        w_new = w - t * delta_w(p, phi, w)\n",
        "        i = i + 1"
      ],
      "metadata": {
        "id": "0na2nbw8ZBbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load values of id\n",
        "id_test = np.loadtxt('test.csv', dtype='int', delimiter=',',\n",
        "                         skiprows=1, usecols=0, ndmin=2)\n",
        "\n",
        "    # Calculate y for test data\n",
        "y_test = np.exp(np.dot(phi_test, w_new))\n",
        "\n",
        "    # Save the ids and y\n",
        "np.savetxt(fname, np.concatenate((id_test, y_test), axis=1),\n",
        "               delimiter=',', fmt=['%d', '%f'], header='ID,MEDV', comments='')"
      ],
      "metadata": {
        "id": "B-W1rSX5ZFGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}